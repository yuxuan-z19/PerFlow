{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PerFlow A domain-specific framework for performance analysis of large-scale parallel programs (\u9762\u5411\u6027\u80fd\u5206\u6790\u9886\u57df\u7684\u7f16\u7a0b\u6846\u67b6) Quick Links (\u5feb\u901f\u94fe\u63a5) Github (\u6e90\u7801\u5730\u5740) About (\u5173\u4e8ePerFlow) User Guide (\u4f7f\u7528\u6307\u5357) Documentation (\u6587\u6863) Introduction (\u7b80\u4ecb) PerFlow\u662f\u4e00\u5957\u96c6\u6210\u4e86\u6027\u80fd\u6570\u636e\u91c7\u96c6\u548c\u5206\u6790\u7684\u5168\u94fe\u5de5\u5177\u3002 \u5728\u6027\u80fd\u6570\u636e\u91c7\u96c6\u9636\u6bb5\uff0cPerFlow\u7ed3\u5408\u57fa\u4e8e\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684\u9759\u6001\u5206\u6790\u548c\u57fa\u4e8e\u91c7\u6837\u7684\u52a8\u6001\u5206\u6790\u3002 \u5728\u6027\u80fd\u6570\u636e\u5206\u6790\u9636\u6bb5\uff0cPerFlow\u5c06\u6027\u80fd\u6570\u636e\u7ec4\u7ec7\u6210\u4e00\u79cd\u56fe\uff08\u6027\u80fd\u62bd\u8c61\u56fe\uff09\uff0c\u56fe\u4e2d\u7684\u70b9\u4ee3\u8868\u4ee3\u7801\u6bb5\uff0c\u8fb9\u4ee3\u8868\u4ee3\u7801\u6bb5\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5305\u62ec\u6570\u636e\u4f9d\u8d56\u3001\u63a7\u5236\u4f9d\u8d56\u3001\u7ebf\u7a0b\u95f4\u9501\u4f9d\u8d56\u548c\u8fdb\u7a0b\u95f4\u901a\u4fe1\u4f9d\u8d56\u7b49\u3002 \u540c\u65f6\uff0cPerFlow\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u6d41\u56fe\u7684\u7f16\u7a0b\u62bd\u8c61\uff0c\u5141\u8bb8\u7528\u6237\u4f7f\u7528\u6570\u636e\u6d41\u56fe\u8868\u793a\u6027\u80fd\u5206\u6790\u4efb\u52a1\u7684\u6574\u4e2a\u8fc7\u7a0b\u3002 \u5f00\u53d1\u4eba\u5458\u53ef\u4ee5\u901a\u8fc7PerFlow\u63d0\u4f9b\u7684Python\u7f16\u7a0b\u63a5\u53e3\uff0c\u81ea\u5b9a\u4e49\u5206\u6790\u6027\u80fd\u6570\u636e\uff0c\u5e76\u53ef\u4ee5\u4e0enumpy\u3001sklearn\u7b49\u6570\u636e\u5206\u6790\u5305\u7ed3\u5408\u4f7f\u7528\u3002 PerFlow\u7684\u4f18\u70b9\u662f\uff1a\u6709\u6548\u964d\u4f4e\u5f00\u53d1\u4eba\u5458\u624b\u5199\u6027\u80fd\u5206\u6790\u4efb\u52a1\u7684\u590d\u6742\u5ea6\u3002 Performance analysis is widely used to identify performance issues of parallel applications. However, complex communications and data dependence, as well as the interactions between different kinds of performance issues make high-efficiency performance analysis even harder. Although a large number of performance tools have been designed, accurately pinpointing root causes for such complex performance issues still needs specific in-depth analysis. To implement each such analysis, significant human efforts and domain knowledge are normally required. To reduce the burden of implementing accurate performance analysis, we propose a domain specific programming framework, named PerFlow. PerFlow abstracts the step-by-step process of performance analysis as a dataflow graph. This dataflow graph consists of main performance analysis sub-tasks, called passes, which can either be provided by PerFlow\u2019s built-in analysis library, or be implemented by developers to meet their requirements. Moreover, to achieve effective analysis, we propose a Program Abstraction Graph to represent the performance of a program execution and then leverage various graph algorithms to automate the analysis. We demonstrate the efficacy of PerFlow by three case studies of real-world applications with up to 700K lines of code. Results show that PerFlow significantly eases the implementation of customized analysis tasks. In addition, PerFlow is able to perform analysis and locate performance bugs automatically and effectively. How to Use (\u7b80\u5355\u4f7f\u7528\u65b9\u6cd5) import perflow as pf # Static binary analysis and dynamic profiling pag = pf.run(bin = 'a.out', cmd = 'mpirun -np 4 ./a.out') # Hotspot analysis results = pf.hotspot_detection(pag.vs) # Report the results pf.report(results) Publications (\u53d1\u8868) Yuyang Jin, Haojie Wang, Runxin Zhong, Chen Zhang, Jidong Zhai . PerFlow: a domain specific framework for automatic performance analysis of parallel applications[C]//Proceedings of the 27th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming. 2022: 177-191. [PDF] @inproceedings {jin2022perflow, title = {PerFlow: a domain specific framework for automatic performance analysis of parallel applications}, author = {Jin, Yuyang and Wang, Haojie and Zhong, Runxin and Zhang, Chen and Zhai, Jidong}, booktitle = {Proceedings of the 27th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming}, pages = {177--191}, year = {2022} } License","title":"Home"},{"location":"#perflow","text":"A domain-specific framework for performance analysis of large-scale parallel programs (\u9762\u5411\u6027\u80fd\u5206\u6790\u9886\u57df\u7684\u7f16\u7a0b\u6846\u67b6)","title":"PerFlow"},{"location":"#quick-links","text":"Github (\u6e90\u7801\u5730\u5740) About (\u5173\u4e8ePerFlow) User Guide (\u4f7f\u7528\u6307\u5357) Documentation (\u6587\u6863)","title":"Quick Links (\u5feb\u901f\u94fe\u63a5)"},{"location":"#introduction","text":"PerFlow\u662f\u4e00\u5957\u96c6\u6210\u4e86\u6027\u80fd\u6570\u636e\u91c7\u96c6\u548c\u5206\u6790\u7684\u5168\u94fe\u5de5\u5177\u3002 \u5728\u6027\u80fd\u6570\u636e\u91c7\u96c6\u9636\u6bb5\uff0cPerFlow\u7ed3\u5408\u57fa\u4e8e\u4e8c\u8fdb\u5236\u6587\u4ef6\u7684\u9759\u6001\u5206\u6790\u548c\u57fa\u4e8e\u91c7\u6837\u7684\u52a8\u6001\u5206\u6790\u3002 \u5728\u6027\u80fd\u6570\u636e\u5206\u6790\u9636\u6bb5\uff0cPerFlow\u5c06\u6027\u80fd\u6570\u636e\u7ec4\u7ec7\u6210\u4e00\u79cd\u56fe\uff08\u6027\u80fd\u62bd\u8c61\u56fe\uff09\uff0c\u56fe\u4e2d\u7684\u70b9\u4ee3\u8868\u4ee3\u7801\u6bb5\uff0c\u8fb9\u4ee3\u8868\u4ee3\u7801\u6bb5\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5305\u62ec\u6570\u636e\u4f9d\u8d56\u3001\u63a7\u5236\u4f9d\u8d56\u3001\u7ebf\u7a0b\u95f4\u9501\u4f9d\u8d56\u548c\u8fdb\u7a0b\u95f4\u901a\u4fe1\u4f9d\u8d56\u7b49\u3002 \u540c\u65f6\uff0cPerFlow\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u6d41\u56fe\u7684\u7f16\u7a0b\u62bd\u8c61\uff0c\u5141\u8bb8\u7528\u6237\u4f7f\u7528\u6570\u636e\u6d41\u56fe\u8868\u793a\u6027\u80fd\u5206\u6790\u4efb\u52a1\u7684\u6574\u4e2a\u8fc7\u7a0b\u3002 \u5f00\u53d1\u4eba\u5458\u53ef\u4ee5\u901a\u8fc7PerFlow\u63d0\u4f9b\u7684Python\u7f16\u7a0b\u63a5\u53e3\uff0c\u81ea\u5b9a\u4e49\u5206\u6790\u6027\u80fd\u6570\u636e\uff0c\u5e76\u53ef\u4ee5\u4e0enumpy\u3001sklearn\u7b49\u6570\u636e\u5206\u6790\u5305\u7ed3\u5408\u4f7f\u7528\u3002 PerFlow\u7684\u4f18\u70b9\u662f\uff1a\u6709\u6548\u964d\u4f4e\u5f00\u53d1\u4eba\u5458\u624b\u5199\u6027\u80fd\u5206\u6790\u4efb\u52a1\u7684\u590d\u6742\u5ea6\u3002 Performance analysis is widely used to identify performance issues of parallel applications. However, complex communications and data dependence, as well as the interactions between different kinds of performance issues make high-efficiency performance analysis even harder. Although a large number of performance tools have been designed, accurately pinpointing root causes for such complex performance issues still needs specific in-depth analysis. To implement each such analysis, significant human efforts and domain knowledge are normally required. To reduce the burden of implementing accurate performance analysis, we propose a domain specific programming framework, named PerFlow. PerFlow abstracts the step-by-step process of performance analysis as a dataflow graph. This dataflow graph consists of main performance analysis sub-tasks, called passes, which can either be provided by PerFlow\u2019s built-in analysis library, or be implemented by developers to meet their requirements. Moreover, to achieve effective analysis, we propose a Program Abstraction Graph to represent the performance of a program execution and then leverage various graph algorithms to automate the analysis. We demonstrate the efficacy of PerFlow by three case studies of real-world applications with up to 700K lines of code. Results show that PerFlow significantly eases the implementation of customized analysis tasks. In addition, PerFlow is able to perform analysis and locate performance bugs automatically and effectively.","title":"Introduction (\u7b80\u4ecb)"},{"location":"#how-to-use","text":"import perflow as pf # Static binary analysis and dynamic profiling pag = pf.run(bin = 'a.out', cmd = 'mpirun -np 4 ./a.out') # Hotspot analysis results = pf.hotspot_detection(pag.vs) # Report the results pf.report(results)","title":"How to Use (\u7b80\u5355\u4f7f\u7528\u65b9\u6cd5)"},{"location":"#publications","text":"Yuyang Jin, Haojie Wang, Runxin Zhong, Chen Zhang, Jidong Zhai . PerFlow: a domain specific framework for automatic performance analysis of parallel applications[C]//Proceedings of the 27th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming. 2022: 177-191. [PDF] @inproceedings {jin2022perflow, title = {PerFlow: a domain specific framework for automatic performance analysis of parallel applications}, author = {Jin, Yuyang and Wang, Haojie and Zhong, Runxin and Zhang, Chen and Zhai, Jidong}, booktitle = {Proceedings of the 27th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming}, pages = {177--191}, year = {2022} }","title":"Publications (\u53d1\u8868)"},{"location":"#license","text":"","title":"License"},{"location":"contact/","text":"Contact If you have any comments or questions regarding the use and installation of PerFlow, or want to report a bug you discovered, please send an email to ME (malito: jinyuyang AT tsinghua.edu.cn).","title":"Contact"},{"location":"contact/#contact","text":"If you have any comments or questions regarding the use and installation of PerFlow, or want to report a bug you discovered, please send an email to ME (malito: jinyuyang AT tsinghua.edu.cn).","title":"Contact"},{"location":"about/about/","text":"About PerFlow","title":"About PerFlow"},{"location":"about/about/#about-perflow","text":"","title":"About PerFlow"},{"location":"about/functionality/","text":"Functionality","title":"Functionality"},{"location":"about/functionality/#functionality","text":"","title":"Functionality"},{"location":"about/overview/","text":"Overview","title":"Overview"},{"location":"about/overview/#overview","text":"","title":"Overview"},{"location":"documentation/builtinmodel/","text":"","title":"Builtin Models"},{"location":"documentation/builtinpass/","text":"","title":"Builtin Passes"},{"location":"documentation/documentation/","text":"Documenation Python API Builtin Passes Builtin Models","title":"Documentation"},{"location":"documentation/documentation/#documenation","text":"Python API Builtin Passes Builtin Models","title":"Documenation"},{"location":"documentation/pythonapi/","text":"","title":"Python API"},{"location":"examples/example/","text":"Examples","title":"Examples"},{"location":"examples/example/#examples","text":"","title":"Examples"},{"location":"userguide/firstrun/","text":"Using PerFlow There are two main ways for developers to implement specific analysis tasks with PerFlow\u2019s APIs: using built-in models and customize models with built-in passes. Using Models Developers can directly use built-in models to obtain related performance analysis reports. example1 Building Customized Models PerFlow provides a built-in performance analysis pass library for building customized models. For scenarios where analysis tasks have already been designed, the following example shows a complete process of implementation. example2 For scenarios in which developers do not know what analysis to apply, PerFlow supports an interactive mode. It is advisable to first use a general built-in analysis pass, such as hotspot detection. The output of the previous pass will provide some insights to help determine or design the next passes. Then analysts can add other analysis passes into models step by step. Finally, models are generated according to detailed analysis. Writing Customized Passes If built-in passes cannot satisfy the demands, developers need to write customized passes and combine these user-defined passes with other built-in passes to build models. example3","title":"Using PerFlow"},{"location":"userguide/firstrun/#using-perflow","text":"There are two main ways for developers to implement specific analysis tasks with PerFlow\u2019s APIs: using built-in models and customize models with built-in passes.","title":"Using PerFlow"},{"location":"userguide/firstrun/#using-models","text":"Developers can directly use built-in models to obtain related performance analysis reports. example1","title":"Using Models"},{"location":"userguide/firstrun/#building-customized-models","text":"PerFlow provides a built-in performance analysis pass library for building customized models. For scenarios where analysis tasks have already been designed, the following example shows a complete process of implementation. example2 For scenarios in which developers do not know what analysis to apply, PerFlow supports an interactive mode. It is advisable to first use a general built-in analysis pass, such as hotspot detection. The output of the previous pass will provide some insights to help determine or design the next passes. Then analysts can add other analysis passes into models step by step. Finally, models are generated according to detailed analysis.","title":"Building Customized Models"},{"location":"userguide/firstrun/#writing-customized-passes","text":"If built-in passes cannot satisfy the demands, developers need to write customized passes and combine these user-defined passes with other built-in passes to build models. example3","title":"Writing Customized Passes"},{"location":"userguide/firstrun/#_1","text":"","title":""},{"location":"userguide/gettingstarted/","text":"Getting Started Installation (\u5982\u4f55\u5b89\u88c5) Using Perflow (\u5982\u4f55\u4f7f\u7528PerFlow) Customizing performance analysis tasks (\u5982\u4f55\u81ea\u5b9a\u4e49\u6027\u80fd\u5206\u6790\u4efb\u52a1)","title":"Getting Started"},{"location":"userguide/gettingstarted/#getting-started","text":"Installation (\u5982\u4f55\u5b89\u88c5) Using Perflow (\u5982\u4f55\u4f7f\u7528PerFlow) Customizing performance analysis tasks (\u5982\u4f55\u81ea\u5b9a\u4e49\u6027\u80fd\u5206\u6790\u4efb\u52a1)","title":"Getting Started"},{"location":"userguide/installation/","text":"Installation Dependencies PerFlow is dependent on: Dyninst Boost (Boost will be installed automatically with Dyninst) PAPI libunwind igraph cmake >= 3.16 Dyninst and PAPI need user to build themselves. igraph has been integrated into PerFlow as submodule. git submodule update --init You can build dependencies from source codes or build dependencies with Spack (The recommended way to build Dyninst (with Boost) and PAPI is to use Spack) spack install dyninst # boost will be installed at the same time spack install papi spack install libunwind Environment Setting If your dependencies are built from source codes, please use the following scripts to load the dependence libraries: PREFIX=/home/jinyuyang/build DEPLIST=\"papi-6.0.0 dyninst-10.1.0 libunwind-1.6.0\" for dep in $DEPLIST do export PATH=${PREFIX}/${dep}/bin64:${PREFIX}/${dep}/bin:$PATH export INCLUDE=${PREFIX}/${dep}/include64:${PREFIX}/${dep}/include:$INCLUDE export C_INCLUDE_PATH=${PREFIX}/${dep}/include64:${PREFIX}/${dep}/include:$C_INCLUDE_PATH export CPLUS_INCLUDE_PATH=${PREFIX}/${dep}/include64:${PREFIX}/${dep}/include:$CPLUS_INCLUDE_PATH export LIBRARY_PATH=${PREFIX}/${dep}/lib64:${PREFIX}/${dep}/lib:$LIBRARY_PATH export LD_LIBRARY_PATH=${PREFIX}/${dep}/lib64:${PREFIX}/${dep}/lib:$LD_LIBRARY_PATH done If your dependencies are built with spack, please use the following scripts to load the dependence libraries: # before building PerFlow spack load dyninst # boost will be loaded at the same time spack load papi spack load libunwind Build PerFlow If your dependencies are built from source codes, the cmake commands for PerFlow would be like: cmake .. -DBOOST_ROOT=/path_to_your_boost_install_dir -DDyninst_DIR=/path_to_your_dyninst_install_dir/lib/cmake/Dyninst -DPAPI_PREFIX=/path_to_your_papi_install_dir # You should make sure that there is `DyninstConfig.cmake` in /path_to_your_dyninst_install_dir/lib/cmake/Dyninst # And there is `include` `lib` in /path_to_your_papi_install_dir # And there is `include` `lib` in /path_to_your_boost_install_dir, `boost` in /path_to_your_boost_install_dir/include Note that if dyninst is built from source, the boost will be downloaded and installed automatically with it, in the install directory of dyninst. cmake .. -DBOOST_ROOT=/path_to_your_dyninst_install_dir -DDyninst_DIR=/path_to_your_dyninst_install_dir/lib/cmake/Dyninst -DPAPI_PREFIX=/path_to_your_papi_install_dir If your dependencies are built with spack, the cmake commands for PerFlow would be like: # build mkdir build cd build cmake ..","title":"Installation"},{"location":"userguide/installation/#installation","text":"","title":"Installation"},{"location":"userguide/installation/#dependencies","text":"PerFlow is dependent on: Dyninst Boost (Boost will be installed automatically with Dyninst) PAPI libunwind igraph cmake >= 3.16 Dyninst and PAPI need user to build themselves. igraph has been integrated into PerFlow as submodule. git submodule update --init You can build dependencies from source codes or build dependencies with Spack (The recommended way to build Dyninst (with Boost) and PAPI is to use Spack) spack install dyninst # boost will be installed at the same time spack install papi spack install libunwind","title":"Dependencies"},{"location":"userguide/installation/#environment-setting","text":"If your dependencies are built from source codes, please use the following scripts to load the dependence libraries: PREFIX=/home/jinyuyang/build DEPLIST=\"papi-6.0.0 dyninst-10.1.0 libunwind-1.6.0\" for dep in $DEPLIST do export PATH=${PREFIX}/${dep}/bin64:${PREFIX}/${dep}/bin:$PATH export INCLUDE=${PREFIX}/${dep}/include64:${PREFIX}/${dep}/include:$INCLUDE export C_INCLUDE_PATH=${PREFIX}/${dep}/include64:${PREFIX}/${dep}/include:$C_INCLUDE_PATH export CPLUS_INCLUDE_PATH=${PREFIX}/${dep}/include64:${PREFIX}/${dep}/include:$CPLUS_INCLUDE_PATH export LIBRARY_PATH=${PREFIX}/${dep}/lib64:${PREFIX}/${dep}/lib:$LIBRARY_PATH export LD_LIBRARY_PATH=${PREFIX}/${dep}/lib64:${PREFIX}/${dep}/lib:$LD_LIBRARY_PATH done If your dependencies are built with spack, please use the following scripts to load the dependence libraries: # before building PerFlow spack load dyninst # boost will be loaded at the same time spack load papi spack load libunwind","title":"Environment Setting"},{"location":"userguide/installation/#build-perflow","text":"If your dependencies are built from source codes, the cmake commands for PerFlow would be like: cmake .. -DBOOST_ROOT=/path_to_your_boost_install_dir -DDyninst_DIR=/path_to_your_dyninst_install_dir/lib/cmake/Dyninst -DPAPI_PREFIX=/path_to_your_papi_install_dir # You should make sure that there is `DyninstConfig.cmake` in /path_to_your_dyninst_install_dir/lib/cmake/Dyninst # And there is `include` `lib` in /path_to_your_papi_install_dir # And there is `include` `lib` in /path_to_your_boost_install_dir, `boost` in /path_to_your_boost_install_dir/include Note that if dyninst is built from source, the boost will be downloaded and installed automatically with it, in the install directory of dyninst. cmake .. -DBOOST_ROOT=/path_to_your_dyninst_install_dir -DDyninst_DIR=/path_to_your_dyninst_install_dir/lib/cmake/Dyninst -DPAPI_PREFIX=/path_to_your_papi_install_dir If your dependencies are built with spack, the cmake commands for PerFlow would be like: # build mkdir build cd build cmake ..","title":"Build PerFlow"},{"location":"userguide/performanceanalysis/","text":"Customizing performance analysis with PerFlow Here we provide more examples to show how to customizing performance analysis passes and models: Hotspot detection pass Hotspot detection refers to identifying the code snippets with the highest value of specific metrics, such as total execution cycles, cache misses, and instruction count, etc. The most common hotspot detection is to identify the most time-consuming code snippets, whose specific metric is total execution cycles or execution time. The following code shows a hotspot detection pass. # Define an \"hotspot detection\" pass # Input: The vertex set of a PAG - V # Sorting metric - m # The number of returned vertices - n # Output: Hotspot vertex set def hotspot(V, m, n): return V.sort_by(m).top(n) Performance differential analysis pass Performance differential analysis refers to a comparison of program performance conducted under the independent variables of input data, parameters, or different executions. The comparison helps analysts understand the trend of performance as the input changes. The performance difference can be intuitively represented on a top-down view of PAG, and we leverage the graph difference to perform differential analysis. Graph difference intuitively shows the changes in performance between program runs with different inputs. # Define a \"differential analysis\" pass # Input: Vertex sets of two PAGs - V1, V2 # Output: A set of difference vertices def differential_analysis(V1, V2): V_res = [] for (v1, v2) in (V1, V2): v = pflow.vertex() for metric in v1.metrics: v[metric] = v1[metric] - v2[metric] V_res.append(v) 11 return V_res Causal analysis pass Performance bugs can propagate through complex inter-process communications as well as inter-thread locks, and lead to many secondary performance bugs, which makes root cause detection even harder. Paths that consist of a parallel view of PAG\u2019s edges can well represent correlations across these performance bugs in different processes and threads. We leverage a graph algorithm, lowest common ancestor (LCA), and specific restrictions to detect the correlations and thus achieve the purpose of causal analysis. The goal of the LCA algorithm is to search the deepest vertex that has both v and w as descendants in a tree or directed acyclic graph. The causal analysis pass is designed based on the LCA algorithm. # Define a \"causal analysis\" pass # Input: A set of vertices with performance bugs - V # Output: A set of vertices that cause the bugs def casual_analysis(V) V_res, S = [], [] # S for scanned vertices for (v1, v2) in (V, V): if v1 != v2 and v1 not in S and v2 not in S: # v1 and v2 are regarded as descendants v, path = pflow.lowest_common_ancestor(v1, v2) # v is the detected lowest common ancestor 11 # path is an edge set if v in V: V_res.append(v) return V_res Contention detection pass Contention refers to a conflict over a shared resource across processes or threads, which leads to a negative impact on the performance of processes or threads competing for the resource. It can cause several kinds of misbehavior, such as unwanted synchronization or periodicity, deadlock, livelock, and many more, which need expensive human efforts to be detected. We observe that misbehaviors have specific patterns on the parallel view of PAGs. Subgraph matching, which searches all embeddings of a subgraph query in a large graph, is leveraged to search these specific patterns on the PAGs and detect resource contention. The contention detection pass determines whether resource contention exists in the vertices of input sets. The input of a contention detection pass is a set of vertices detected by the previous pass, while the outputs are the detected subgraph embeddings. We define a set of candidate subgraphs to represent resource contention patterns. Then we identify resource contentions by searching the embeddings of candidate subgraphs around the vertices of the input set. # Define a \"contention detection\" pass # Input: Vertex set - V # Output: Subgraph embeddings def contention_detection(V): V_res = [] # Build a candidate subgraph with contention pattern sub_pag = pflow.graph() sub_pag.add_vertices([(1,\"A\"), (2,\"B\"), (3,\"C\"), (4,\"D\"), (5,\"E\")]) sub_pag.add_edges([(1,3), (2,3), (3,4), (3,5)]) # Execute subgraph matching algorithm V_ebd, E_ebd = pflow.subgraph_matching(V.pag, sub_pag) return V_ebd, E_ebd Scalability analysis model ( ScalAna ) The scalability analysis task in ScalAna first detects code snippets with scaling loss and imbalance, then finds the complex dependence between the detected code snippets by a back- tracking algorithm, and finally identifies the root causes of scaling loss. We decompose the scalability analysis task into multiple steps. Most of the steps can be completed with PerFlow\u2019s built-in passes, and we only need to implement the backtracking step as a user-defined pass. We build the scalability analysis model, containing three built-in passes (differential analysis pass, hotspot detection pass, and imbalance analysis pass), a user-defined pass (backtracking analysis pass), a union operation, and a report module. # Define a \"scalability analysis\" paradigm # Input: PAGs of two program runs - PAG1, PAG2 def scalability_analysis_paradigm(PAG1, PAG2): # Part 1: Define a \"backtracking analysis\" pass # Input: A set of vertices with performance bugs - V # Output: Vertices and edges on backtracking paths def backtracking_analysis(V): V_bt, E_bt, S = [], [], [] # S for scanned vertices for v in V: if v not in S: S.append(v) in_es = v.es.select(IN_EDGE) while len(in_es) != 0 and v[name] not in pflow.COLL_COMM: if v[type] == pflow.MPI: e = in_es.select(type = pflow.COMM) elif v[type] == pflow.LOOP or v[type] == pflow.BRANCH: e = in_es.select(type = pflow.CTRL_FLOW) else e = in_es.select(type = pflow.DATA_FLOW) V_bt.append(v) E_bt.append(e) v = e.src return V_bt, E_bt # Part 2: Build the PerFlowGraph of scalability analysis paradigm V1, V2 = PAG1.vs, PAG2.vs V_diff = pflow.differential_analysis(V1, V2) V_hot = pflow.hotspot_detection(V_diff) V_imb = pflow.imbalance_analysis(V_diff) V_union = pflow.union(V_hot, V_imb) V_bt, E_bt = backtracking_analysis(V_union) attrs = [\"name\", \"time\", \"dbg-info\", \"pmu\"] pflow.report([V_bt, E_bt], attrs) # Use the scalability analysis paradigm pag_p4 = pflow.run(bin = \"./a.out\", cmd = \"mpirun -np 4 ./a.out\") pag_p64 = pflow.run(bin = \"./a.out\", cmd = \"mpirun -np 64 ./a.out\") scalability_analysis_paradigm(pag_p4, pag_p64) The code above shows the implementation of the scalability anal- ysis paradigm, which consists of two parts: (1) Writing a backtracking analysis pass. We first write a backtracking analysis pass, which is not provided by our built-in pass library. This pass implements a backward traversal through communications, and control/data flow with several graph operation APIs, including neighbor acquisition ( v.es at Line 13), edge filter ( select() at Line 13, 17, 20, and 22), attribute access ( v[...] at Line 15-16, 18-19), and source vertex acquisition ( e.src at Line 25). (2) Building the scalability analysis model. Then, we build a PerFlowGraph with built-in and user-defined passes. The differential analysis pass (Line 30) takes two executions (i.e., a small-scale run and a large-scale run) as input, and outputs all vertices with their scaling loss. Then the hotspot analysis pass (Line 31) outputs vertices with the poorest scalability, while the imbalance analysis pass (Line 32) outputs imbalanced vertices between different processes. The union operation (Line 33) merges two sets (outputs of the hotspot analysis pass and the imbalance analysis pass) as the input of the backtracking analysis pass (Line 34). Finally, the backtracking paths and the root causes of scalability are stored in ( V_bt , E_bt ) and reported (Line 36).","title":"Customized Performance Analysis"},{"location":"userguide/performanceanalysis/#customizing-performance-analysis-with-perflow","text":"Here we provide more examples to show how to customizing performance analysis passes and models:","title":"Customizing performance analysis with PerFlow"},{"location":"userguide/performanceanalysis/#hotspot-detection-pass","text":"Hotspot detection refers to identifying the code snippets with the highest value of specific metrics, such as total execution cycles, cache misses, and instruction count, etc. The most common hotspot detection is to identify the most time-consuming code snippets, whose specific metric is total execution cycles or execution time. The following code shows a hotspot detection pass. # Define an \"hotspot detection\" pass # Input: The vertex set of a PAG - V # Sorting metric - m # The number of returned vertices - n # Output: Hotspot vertex set def hotspot(V, m, n): return V.sort_by(m).top(n)","title":"Hotspot detection pass"},{"location":"userguide/performanceanalysis/#performance-differential-analysis-pass","text":"Performance differential analysis refers to a comparison of program performance conducted under the independent variables of input data, parameters, or different executions. The comparison helps analysts understand the trend of performance as the input changes. The performance difference can be intuitively represented on a top-down view of PAG, and we leverage the graph difference to perform differential analysis. Graph difference intuitively shows the changes in performance between program runs with different inputs. # Define a \"differential analysis\" pass # Input: Vertex sets of two PAGs - V1, V2 # Output: A set of difference vertices def differential_analysis(V1, V2): V_res = [] for (v1, v2) in (V1, V2): v = pflow.vertex() for metric in v1.metrics: v[metric] = v1[metric] - v2[metric] V_res.append(v) 11 return V_res","title":"Performance differential analysis pass"},{"location":"userguide/performanceanalysis/#causal-analysis-pass","text":"Performance bugs can propagate through complex inter-process communications as well as inter-thread locks, and lead to many secondary performance bugs, which makes root cause detection even harder. Paths that consist of a parallel view of PAG\u2019s edges can well represent correlations across these performance bugs in different processes and threads. We leverage a graph algorithm, lowest common ancestor (LCA), and specific restrictions to detect the correlations and thus achieve the purpose of causal analysis. The goal of the LCA algorithm is to search the deepest vertex that has both v and w as descendants in a tree or directed acyclic graph. The causal analysis pass is designed based on the LCA algorithm. # Define a \"causal analysis\" pass # Input: A set of vertices with performance bugs - V # Output: A set of vertices that cause the bugs def casual_analysis(V) V_res, S = [], [] # S for scanned vertices for (v1, v2) in (V, V): if v1 != v2 and v1 not in S and v2 not in S: # v1 and v2 are regarded as descendants v, path = pflow.lowest_common_ancestor(v1, v2) # v is the detected lowest common ancestor 11 # path is an edge set if v in V: V_res.append(v) return V_res","title":"Causal analysis pass"},{"location":"userguide/performanceanalysis/#contention-detection-pass","text":"Contention refers to a conflict over a shared resource across processes or threads, which leads to a negative impact on the performance of processes or threads competing for the resource. It can cause several kinds of misbehavior, such as unwanted synchronization or periodicity, deadlock, livelock, and many more, which need expensive human efforts to be detected. We observe that misbehaviors have specific patterns on the parallel view of PAGs. Subgraph matching, which searches all embeddings of a subgraph query in a large graph, is leveraged to search these specific patterns on the PAGs and detect resource contention. The contention detection pass determines whether resource contention exists in the vertices of input sets. The input of a contention detection pass is a set of vertices detected by the previous pass, while the outputs are the detected subgraph embeddings. We define a set of candidate subgraphs to represent resource contention patterns. Then we identify resource contentions by searching the embeddings of candidate subgraphs around the vertices of the input set. # Define a \"contention detection\" pass # Input: Vertex set - V # Output: Subgraph embeddings def contention_detection(V): V_res = [] # Build a candidate subgraph with contention pattern sub_pag = pflow.graph() sub_pag.add_vertices([(1,\"A\"), (2,\"B\"), (3,\"C\"), (4,\"D\"), (5,\"E\")]) sub_pag.add_edges([(1,3), (2,3), (3,4), (3,5)]) # Execute subgraph matching algorithm V_ebd, E_ebd = pflow.subgraph_matching(V.pag, sub_pag) return V_ebd, E_ebd","title":"Contention detection pass"},{"location":"userguide/performanceanalysis/#scalability-analysis-model-scalana","text":"The scalability analysis task in ScalAna first detects code snippets with scaling loss and imbalance, then finds the complex dependence between the detected code snippets by a back- tracking algorithm, and finally identifies the root causes of scaling loss. We decompose the scalability analysis task into multiple steps. Most of the steps can be completed with PerFlow\u2019s built-in passes, and we only need to implement the backtracking step as a user-defined pass. We build the scalability analysis model, containing three built-in passes (differential analysis pass, hotspot detection pass, and imbalance analysis pass), a user-defined pass (backtracking analysis pass), a union operation, and a report module. # Define a \"scalability analysis\" paradigm # Input: PAGs of two program runs - PAG1, PAG2 def scalability_analysis_paradigm(PAG1, PAG2): # Part 1: Define a \"backtracking analysis\" pass # Input: A set of vertices with performance bugs - V # Output: Vertices and edges on backtracking paths def backtracking_analysis(V): V_bt, E_bt, S = [], [], [] # S for scanned vertices for v in V: if v not in S: S.append(v) in_es = v.es.select(IN_EDGE) while len(in_es) != 0 and v[name] not in pflow.COLL_COMM: if v[type] == pflow.MPI: e = in_es.select(type = pflow.COMM) elif v[type] == pflow.LOOP or v[type] == pflow.BRANCH: e = in_es.select(type = pflow.CTRL_FLOW) else e = in_es.select(type = pflow.DATA_FLOW) V_bt.append(v) E_bt.append(e) v = e.src return V_bt, E_bt # Part 2: Build the PerFlowGraph of scalability analysis paradigm V1, V2 = PAG1.vs, PAG2.vs V_diff = pflow.differential_analysis(V1, V2) V_hot = pflow.hotspot_detection(V_diff) V_imb = pflow.imbalance_analysis(V_diff) V_union = pflow.union(V_hot, V_imb) V_bt, E_bt = backtracking_analysis(V_union) attrs = [\"name\", \"time\", \"dbg-info\", \"pmu\"] pflow.report([V_bt, E_bt], attrs) # Use the scalability analysis paradigm pag_p4 = pflow.run(bin = \"./a.out\", cmd = \"mpirun -np 4 ./a.out\") pag_p64 = pflow.run(bin = \"./a.out\", cmd = \"mpirun -np 64 ./a.out\") scalability_analysis_paradigm(pag_p4, pag_p64) The code above shows the implementation of the scalability anal- ysis paradigm, which consists of two parts: (1) Writing a backtracking analysis pass. We first write a backtracking analysis pass, which is not provided by our built-in pass library. This pass implements a backward traversal through communications, and control/data flow with several graph operation APIs, including neighbor acquisition ( v.es at Line 13), edge filter ( select() at Line 13, 17, 20, and 22), attribute access ( v[...] at Line 15-16, 18-19), and source vertex acquisition ( e.src at Line 25). (2) Building the scalability analysis model. Then, we build a PerFlowGraph with built-in and user-defined passes. The differential analysis pass (Line 30) takes two executions (i.e., a small-scale run and a large-scale run) as input, and outputs all vertices with their scaling loss. Then the hotspot analysis pass (Line 31) outputs vertices with the poorest scalability, while the imbalance analysis pass (Line 32) outputs imbalanced vertices between different processes. The union operation (Line 33) merges two sets (outputs of the hotspot analysis pass and the imbalance analysis pass) as the input of the backtracking analysis pass (Line 34). Finally, the backtracking paths and the root causes of scalability are stored in ( V_bt , E_bt ) and reported (Line 36).","title":"Scalability analysis model (ScalAna)"}]}